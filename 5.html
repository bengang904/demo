<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />
  <title>竖直居中人脸检测（镜像版）</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      background-color: black;
      overflow: hidden;
      height: 100%;
      width: 100%;
      display: flex;
      justify-content: center; 
      align-items: center; 
    }

    #video, #overlay {
      position: absolute;
      object-fit: contain;
      transform: scaleX(-1); /* 水平镜像 */
      max-width: 700px;
      width: 100%;
      height: auto;
      top: 50%;
      left: 50%;
      transform-origin: center center;
      /* 为了水平镜像和居中，结合translate */
      /* 下面的transform覆盖了上面scaleX，这里改用组合写法 */
    }

    /* 修正 transform，合并 translate 和 scaleX */
    #video {
      transform: translate(-50%, -50%) scaleX(-1);
      z-index: 1;
    }
    #overlay {
      transform: translate(-50%, -50%) scaleX(-1);
      z-index: 2;
      pointer-events: none;
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>

  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const MODEL_URL = 'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights';

    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
      faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL)
    ]).then(startVideo);

    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
      } catch (err) {
        alert("无法访问摄像头：" + err);
      }
    }

    video.addEventListener('loadedmetadata', () => {
      // 设置canvas尺寸和视频的实际尺寸一致，保证绘制精确
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      detectFaces();
    });

    async function detectFaces() {
      const displaySize = { width: canvas.width, height: canvas.height };
      faceapi.matchDimensions(canvas, displaySize);

      async function detectLoop() {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks();

        const resizedDetections = faceapi.resizeResults(detections, displaySize);
        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        faceapi.draw.drawDetections(canvas, resizedDetections);
        faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

        requestAnimationFrame(detectLoop);
      }

      detectLoop();
    }
  </script>
</body>
</html>
