<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
  <title>人像深度估计</title>
  <style>
    body, html {
      margin: 0;
      background: black;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
    }
    canvas, video {
      display: block;
      max-width: 100%;
      height: auto;
    }
  </style>
</head>
<body>

<video id="video" autoplay playsinline style="display:none"></video>
<canvas id="canvas"></canvas>

<!-- TensorFlow.js Core & WebGL -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>

<!-- Depth Estimation Model -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/depth-estimation"></script>

<script>
  async function setup() {
    // 启用 WebGL
    await tf.setBackend('webgl');

    // 获取摄像头
    const video = document.getElementById('video');
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.srcObject = stream;

    await new Promise(resolve => video.onloadedmetadata = resolve);

    const canvas = document.getElementById('canvas');
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');

    // 加载深度估计模型
    const estimator = await depthEstimation.createEstimator(
      depthEstimation.SupportedModels.ARPortraitDepth);

    async function render() {
      const depthMap = await estimator.estimateDepth(video);

      const img = await depthMap.toCanvasImageSource();
      ctx.drawImage(img, 0, 0, canvas.width, canvas.height);

      requestAnimationFrame(render);
    }

    render();
  }

  setup();
</script>

</body>
</html>
