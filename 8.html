<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="utf-8">
  <title>环境声频谱 + YAMNet识别</title>
  <style>
    body {
      font-family: sans-serif;
      background: #111;
      color: #fff;
      text-align: center;
    }
    canvas {
      display: block;
      margin: 20px auto;
      background: #222;
      border: 1px solid #444;
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.17.0"></script>
</head>
<body>
  <h2>实时环境声频谱图 + 声音识别</h2>
  <div id="volume">音量: ...</div>
  <canvas id="canvas" width="600" height="200"></canvas>
  <h3 id="result">正在加载模型...</h3>

  <script>
    const modelUrl = 'https://tfhub.dev/google/tfjs-model/yamnet/tfjs/1';
    let model, classNames;

    async function loadModel() {
      model = await tf.loadGraphModel(modelUrl, { fromTFHub: true });
      const resp = await fetch(modelUrl + '/metadata.json');
      const meta = await resp.json();
      classNames = meta['labels'];
    }

    async function start() {
      await loadModel();
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;

      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');
      const width = canvas.width;
      const height = canvas.height;
      source.connect(analyser);

      // 用 ScriptProcessorNode 获取音频 PCM 数据
      const processor = audioContext.createScriptProcessor(16384, 1, 1);
      source.connect(processor);
      processor.connect(audioContext.destination);

      processor.onaudioprocess = async (e) => {
        const data = e.inputBuffer.getChannelData(0);
        const input = tf.tensor(data).reshape([1, data.length]);
        const scores = model.predict(input);
        const scoresArray = await scores.array();
        tf.dispose([input, scores]);

        const meanScores = scoresArray[0];
        const maxIdx = meanScores.indexOf(Math.max(...meanScores));
        const label = classNames[maxIdx];
        document.getElementById('result').innerText = `识别结果: ${label}`;
      };

      function drawSpectrum() {
        analyser.getByteFrequencyData(dataArray);
        let sum = dataArray.reduce((a, b) => a + b, 0);
        let avg = sum / dataArray.length;
        document.getElementById('volume').innerText = `音量: ${avg.toFixed(2)}`;

        ctx.clearRect(0, 0, width, height);
        let barWidth = width / dataArray.length;
        for (let i = 0; i < dataArray.length; i++) {
          let barHeight = dataArray[i];
          ctx.fillStyle = `rgb(${barHeight + 100}, 50, 150)`;
          ctx.fillRect(i * barWidth, height - barHeight, barWidth - 1, barHeight);
        }
        requestAnimationFrame(drawSpectrum);
      }

      drawSpectrum();
    }

    start().catch(err => {
      console.error('初始化失败：', err);
      alert('请允许访问麦克风才能使用此功能');
    });
  </script>
</body>
</html>
